# -*- coding: utf-8 -*-
import sys
import os
import time
import json
import logging
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('divar_scraper.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ
CONFIG = {
    'output_dir': 'results',
    'phone_number': '09217977178',
    'default_city': 'tehran',
    'default_query': 'Ø®ÙˆØ¯Ø±Ùˆ',
    'max_results': 50,  # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬
    'scroll_pause': 2,  # Ø²Ù…Ø§Ù† ØªÙˆÙ‚Ù Ø¨ÛŒÙ† Ø§Ø³Ú©Ø±ÙˆÙ„ (Ø«Ø§Ù†ÛŒÙ‡)
    'headless': False
}

class RealTimeDivarScraper:
    def __init__(self):
        self.driver = self._init_driver()
        os.makedirs(CONFIG['output_dir'], exist_ok=True)
        self.scraped_data = []

    def _init_driver(self):
        """ØªÙ†Ø¸ÛŒÙ… Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        options = Options()
        options.add_argument("--start-maximized")
        options.add_argument("--disable-blink-features=AutomationControlled")
        
        if CONFIG['headless']:
            options.add_argument("--headless=new")
        
        service = Service('msedgedriver.exe')
        return webdriver.Edge(service=service, options=options)

    def _manual_login(self):
        """ÙˆØ±ÙˆØ¯ Ø¯Ø³ØªÛŒ Ø¨Ù‡ Ø¯ÛŒÙˆØ§Ø±"""
        try:
            self.driver.get("https://divar.ir")
            time.sleep(3)

            # Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù‡Ø±
            try:
                city_btn = WebDriverWait(self.driver, 15).until(
                    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(),'ØªÙ‡Ø±Ø§Ù†')]"))
                )
                city_btn.click()
                time.sleep(2)
            except:
                pass

            print("\nÙ„Ø·ÙØ§Ù‹ Ù…Ø±Ø§Ø­Ù„ ÙˆØ±ÙˆØ¯ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯:")
            print("1. Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ ÙˆØ±ÙˆØ¯ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯")
            print(f"2. Ø´Ù…Ø§Ø±Ù‡ {CONFIG['phone_number']} Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯")
            print("3. Ú©Ø¯ ØªØ£ÛŒÛŒØ¯ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ùˆ ÙˆØ§Ø±Ø¯ Ù†Ù…Ø§ÛŒÛŒØ¯")
            input("Ù¾Ø³ Ø§Ø² ÙˆØ±ÙˆØ¯ Ù…ÙˆÙÙ‚ØŒ Enter Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯...")
            return True
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ±ÙˆØ¯: {str(e)}")
            return False

    def _scroll_to_bottom(self):
        """Ø§Ø³Ú©Ø±ÙˆÙ„ ØµÙØ­Ù‡ ØªØ§ Ø§Ù†ØªÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ…Ø§Ù… Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§"""
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        while True:
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(CONFIG['scroll_pause'])
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

    def _extract_advertisements(self):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² ØµÙØ­Ù‡"""
        soup = BeautifulSoup(self.driver.page_source, 'html.parser')
        ads = []
        
        for item in soup.find_all('div', class_='post-card-item')[1:-1]:
            try:
                title = item.find('h2', class_='post-card-title').text.strip()
                link = item.find('a')['href']
                if not link.startswith('http'):
                    link = f"https://divar.ir{link}"
                
                ads.append({
                    'title': title,
                    'link': link,
                    'timestamp': datetime.now().isoformat()
                })
                
                if len(ads) >= CONFIG['max_results']:
                    break
                    
            except Exception as e:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¢Ú¯Ù‡ÛŒ: {str(e)}")
                continue
        
        return ads

    def _get_phone_number(self, ad_url):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡ ØªÙ„ÙÙ† Ø§Ø² ÛŒÚ© Ø¢Ú¯Ù‡ÛŒ"""
        try:
            self.driver.get(ad_url)
            time.sleep(2)
            
            # Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ Ù†Ù…Ø§ÛŒØ´ ØªÙ…Ø§Ø³
            contact_btn = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, ".post-actions__get-contact"))
            )
            contact_btn.click()
            time.sleep(2)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡
            phone_element = WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "a[href^='tel:']"))
            )
            return phone_element.text
            
        except Exception as e:
            logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡: {str(e)}")
            return None

    def _scrape_real_time_data(self):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ø¯ÛŒÙˆØ§Ø±"""
        try:
            # Ø³Ø§Ø®Øª URL Ø¬Ø³ØªØ¬Ùˆ
            search_url = f"https://divar.ir/s/{CONFIG['default_city']}?q={CONFIG['default_query']}"
            self.driver.get(search_url)
            time.sleep(3)
            
            # Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ…Ø§Ù… Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§
            self._scroll_to_bottom()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒØ³Øª Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§
            ads = self._extract_advertisements()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡ ØªÙ„ÙÙ†â€ŒÙ‡Ø§
            for ad in ads:
                ad['phone'] = self._get_phone_number(ad['link'])
                time.sleep(1)  # ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
                
                # Ù†Ù…Ø§ÛŒØ´ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ù†ØªØ§ÛŒØ¬
                print(f"\nğŸ“Œ Ø¢Ú¯Ù‡ÛŒ Ø¬Ø¯ÛŒØ¯:")
                print(f"Ø¹Ù†ÙˆØ§Ù†: {ad['title']}")
                print(f"Ø´Ù…Ø§Ø±Ù‡: {ad.get('phone', 'ÛŒØ§ÙØª Ù†Ø´Ø¯')}")
                print(f"Ù„ÛŒÙ†Ú©: {ad['link']}")
                
                self.scraped_data.append(ad)
            
            return True
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡: {str(e)}")
            return False

    def _save_results(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ÙØ±Ù…Øª JSON"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"divar_results_{timestamp}.json"
            filepath = os.path.join(CONFIG['output_dir'], filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.scraped_data, f, ensure_ascii=False, indent=4)
            
            logging.info(f"Ù†ØªØ§ÛŒØ¬ Ø¯Ø± {filepath} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
            return filepath
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬: {str(e)}")
            return None

    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        try:
            logging.info("Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ø¯ÛŒÙˆØ§Ø±")
            
            if not self._manual_login():
                raise Exception("ÙˆØ±ÙˆØ¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
            
            if not self._scrape_real_time_data():
                raise Exception("Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡")
            
            self._save_results()
            logging.info("Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
            return True
            
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ Ø§ØµÙ„ÛŒ: {str(e)}")
            return False
            
        finally:
            if hasattr(self, 'driver'):
                self.driver.quit()
                logging.info("Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø³ØªÙ‡ Ø´Ø¯")
            input("\nØ¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ØŒ Ú©Ù„ÛŒØ¯ÛŒ Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯...")

if __name__ == "__main__":
    scraper = RealTimeDivarScraper()
    sys.exit(0 if scraper.run() else 1)